{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLGh2B7Foyf+2fOBQcwJQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suneelcs1615/DeepLearning/blob/main/Unit-03_Convolution%20Neural%20Networks/Demonstration_of_LeNET_5_with_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration of LeNET-5 with Tensorflow\n",
        "This notebook is an Open Educational Resource (OER) developed for teaching and learning purposes. It is released under the Creative Commons Attribution–ShareAlike (CC BY-SA 4.0) International License.\n",
        "\n",
        "This license allows anyone to use, copy, adapt, modify, translate, remix, and redistribute the material in any medium or format, provided proper credit is given to the original author and any modified versions are shared under the same license.\n",
        "\n",
        "---\n",
        "*Citation Format: Demonstration of LeNET-5 with Tensorflow. Open Educational Resource (OER). Licensed under CC BY-SA 4.0*"
      ],
      "metadata": {
        "id": "izVwBOqqVtB7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f9cd707"
      },
      "source": [
        "### 1. Load and Preprocess MNIST Data\n",
        "\n",
        "This section handles the loading of the MNIST dataset, resizing the images from 28x28 to 32x32 (as required by LeNet-5), normalizing pixel values to a [0, 1] range, adding a channel dimension, and one-hot encoding the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f995f9f4",
        "outputId": "b8a0cd5e-2644-4062-ffda-e2b8100f98fc"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Resize from 28x28 to 32x32\n",
        "x_train = np.pad(x_train, ((0,0), (2,2), (2,2)), mode='constant')\n",
        "x_test = np.pad(x_test, ((0,0), (2,2), (2,2)), mode='constant')\n",
        "\n",
        "# Normalize to [0,1] and add channel dimension for grayscale\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = np.expand_dims(x_train, axis=-1)  # shape: (num, 32, 32, 1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f120702"
      },
      "source": [
        "### 2. Define the LeNet-5 Model Architecture\n",
        "\n",
        "This block constructs the LeNet-5 convolutional neural network. It includes convolutional layers (with ReLU activation), max-pooling layers, and fully connected layers, culminating in an output layer with softmax activation for 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc696272",
        "outputId": "ef12116c-b74f-4881-dc5c-a47846540f9c"
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# Input: 32×32 grayscale → Conv Layer: 6 filters of 5×5, ReLU\n",
        "model.add(layers.Conv2D(filters=6, kernel_size=(5,5), activation='relu',\n",
        "input_shape=(32,32,1)))\n",
        "\n",
        "# Pooling Layer: 2×2 max pooling\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Conv Layer: 16 filters of 5×5, ReLU\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(5,5), activation='relu'))\n",
        "\n",
        "# Pooling Layer: 2×2 max pooling\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Flatten before Fully Connected Layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Fully Connected Layer: 120 neurons\n",
        "model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "# Fully Connected Layer: 84 neurons\n",
        "model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "# Output Layer: 10 neurons (digits 0–9) with Softmax\n",
        "model.add(layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8d14dce"
      },
      "source": [
        "### 3. Compile the Model\n",
        "\n",
        "Here, the model is compiled using the Adam optimizer, `categorical_crossentropy` as the loss function (suitable for one-hot encoded labels), and `accuracy` as the metric to monitor during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca66af53"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc8929e9"
      },
      "source": [
        "### 4. Train the Model\n",
        "\n",
        "This section initiates the training process. The model is trained on the preprocessed training data (`x_train`, `y_train`) for 10 epochs, with a batch size of 128. Validation is performed on the test data (`x_test`, `y_test`) after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ff51ad0",
        "outputId": "d5a634eb-8630-40aa-a9f1-e7cc9b65f4f1"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 70ms/step - accuracy: 0.8188 - loss: 0.6143 - val_accuracy: 0.9735 - val_loss: 0.0924\n",
            "Epoch 2/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 73ms/step - accuracy: 0.9699 - loss: 0.0953 - val_accuracy: 0.9729 - val_loss: 0.0777\n",
            "Epoch 3/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - accuracy: 0.9799 - loss: 0.0639 - val_accuracy: 0.9817 - val_loss: 0.0537\n",
            "Epoch 4/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 73ms/step - accuracy: 0.9849 - loss: 0.0491 - val_accuracy: 0.9865 - val_loss: 0.0435\n",
            "Epoch 5/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 68ms/step - accuracy: 0.9868 - loss: 0.0390 - val_accuracy: 0.9851 - val_loss: 0.0486\n",
            "Epoch 6/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9892 - loss: 0.0343 - val_accuracy: 0.9884 - val_loss: 0.0353\n",
            "Epoch 7/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 71ms/step - accuracy: 0.9905 - loss: 0.0290 - val_accuracy: 0.9901 - val_loss: 0.0297\n",
            "Epoch 8/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - accuracy: 0.9926 - loss: 0.0250 - val_accuracy: 0.9894 - val_loss: 0.0340\n",
            "Epoch 9/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 70ms/step - accuracy: 0.9923 - loss: 0.0239 - val_accuracy: 0.9889 - val_loss: 0.0353\n",
            "Epoch 10/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 70ms/step - accuracy: 0.9937 - loss: 0.0193 - val_accuracy: 0.9901 - val_loss: 0.0287\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2ecaaf2a50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "171c20a7"
      },
      "source": [
        "### 5. Evaluate the Model\n",
        "\n",
        "Finally, the trained model's performance is evaluated on the test dataset. The test loss and accuracy are calculated and printed to assess how well the model generalizes to unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "364d40c5",
        "outputId": "c0a45247-f2e6-4b97-f720-ff8e8f107eea"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.01%\n"
          ]
        }
      ]
    }
  ]
}